{% extends "base.html" %}

{% block title %}操作マニュアル - AI Fine-tuning Toolkit{% endblock %}

{% block extra_styles %}
.readme-content {
    background: white;
    padding: 30px;
    border-radius: 10px;
    box-shadow: 0 5px 15px rgba(0,0,0,0.1);
    line-height: 1.6;
    font-size: 16px;
}

.readme-content h1 {
    color: #2c3e50;
    border-bottom: 3px solid #3498db;
    padding-bottom: 10px;
    margin-bottom: 30px;
}

.readme-content h2 {
    color: #34495e;
    border-left: 4px solid #3498db;
    padding-left: 15px;
    margin-top: 40px;
    margin-bottom: 20px;
}

.readme-content h3 {
    color: #2c3e50;
    margin-top: 30px;
    margin-bottom: 15px;
}

.readme-content h4 {
    color: #34495e;
    margin-top: 25px;
    margin-bottom: 12px;
    font-weight: bold;
}

.readme-content p {
    margin-bottom: 15px;
    color: #2c3e50;
}

.readme-content ul, .readme-content ol {
    margin-bottom: 20px;
    padding-left: 30px;
}

.readme-content li {
    margin-bottom: 8px;
    color: #2c3e50;
}

.readme-content code {
    background: #f8f9fa;
    padding: 2px 6px;
    border-radius: 4px;
    font-family: 'Courier New', monospace;
    color: #e74c3c;
}

.readme-content pre {
    background: #2c3e50;
    color: #ecf0f1;
    padding: 20px;
    border-radius: 8px;
    overflow-x: auto;
    margin: 20px 0;
}

.readme-content pre code {
    background: none;
    color: inherit;
    padding: 0;
}

.readme-content blockquote {
    border-left: 4px solid #3498db;
    padding-left: 20px;
    margin: 20px 0;
    color: #7f8c8d;
    font-style: italic;
}

.readme-content table {
    width: 100%;
    border-collapse: collapse;
    margin: 20px 0;
}

.readme-content th, .readme-content td {
    border: 1px solid #ddd;
    padding: 12px;
    text-align: left;
}

.readme-content th {
    background: #3498db;
    color: white;
    font-weight: bold;
}

.readme-content tr:nth-child(even) {
    background: #f8f9fa;
}

.feature-badge {
    display: inline-block;
    background: #3498db;
    color: white;
    padding: 3px 8px;
    border-radius: 4px;
    font-size: 12px;
    margin-left: 5px;
    font-weight: bold;
}

.feature-badge.new {
    background: #e74c3c;
}

.warning-box {
    background: #fff3cd;
    border: 1px solid #ffeab5;
    border-radius: 8px;
    padding: 15px;
    margin: 20px 0;
}

.info-box {
    background: #d1ecf1;
    border: 1px solid #bee5eb;
    border-radius: 8px;
    padding: 15px;
    margin: 20px 0;
}

.success-box {
    background: #d4edda;
    border: 1px solid #c3e6cb;
    border-radius: 8px;
    padding: 15px;
    margin: 20px 0;
}

.emoji {
    font-size: 20px;
    margin-right: 5px;
}
{% endblock %}

{% block content %}
<div class="container mt-5">
    <div class="readme-content">
        <h1>🚀 AI Fine-tuning Toolkit with RAG Integration & Continual Learning</h1>
        
        <p><strong>日本語LLMファインチューニング + RAGシステム + 継続学習統合Webツールキット</strong></p>
        
        <div class="info-box">
            <p><span class="emoji">💡</span>Dockerベースの統合Webインターフェースで、日本語大規模言語モデル（LLM）のファインチューニング、土木道路設計特化型RAGシステム、そしてEWCベースの継続学習を同一プラットフォームで実行できます。単一のポート（8050）で全機能にアクセス可能な革新的なツールキットです。</p>
        </div>

        <h2>🌟 主要機能</h2>
        
        <h3>🌐 統合Webインターフェース（RAG + 継続学習統合済み）</h3>
        <ul>
            <li><strong>単一ポートアクセス</strong>: http://localhost:8050 で全機能利用可能</li>
            <li><strong>ファインチューニング機能</strong>: http://localhost:8050/finetune</li>
            <li><strong>RAG機能</strong>: http://localhost:8050/rag</li>
            <li><strong>継続学習機能</strong>: http://localhost:8050/continual <span class="feature-badge new">NEW</span></li>
            <li><strong>リアルタイム監視</strong>: ファインチューニング進捗の可視化</li>
            <li><strong>モデル管理</strong>: 学習済みモデルの一覧・選択・生成</li>
            <li><strong>データアップロード</strong>: JSONLファイル + PDF文書の簡単アップロード</li>
            <li><strong>システム情報</strong>: GPU使用状況とメモリ監視</li>
            <li><strong>プロフェッショナルデザイン</strong>: 株）テイコクロゴと洗練されたUI</li>
            <li><strong>Ollama統合</strong>: Ollamaモデルの利用とダウンロード</li>
        </ul>

        <h3>🏗️ 土木道路設計特化型RAGシステム <span class="feature-badge new">統合済み</span></h3>
        <ul>
            <li><strong>統合API</strong>: <code>/rag/*</code> エンドポイントで9つのRAG機能を提供</li>
            <li><strong>モデル選択UI</strong>: ファインチューニング済みモデルをRAGで使用可能 <span class="feature-badge new">NEW</span></li>
            <li><strong>ハイブリッド検索</strong>: ベクトル検索 + キーワード検索の統合</li>
            <li><strong>多層リランキング</strong>: Cross-encoder、技術用語、文脈理解による精度向上</li>
            <li><strong>引用機能</strong>: 正確な出典情報付き回答生成</li>
            <li><strong>数値処理</strong>: 設計速度・曲線半径・勾配等の自動抽出・検証</li>
            <li><strong>バージョン管理</strong>: 文書の差分検出・変更履歴追跡</li>
            <li><strong>設計基準チェック</strong>: 道路構造令準拠の適合性検証</li>
            <li><strong>ストリーミング応答</strong>: リアルタイム検索結果表示</li>
            <li><strong>バッチ処理</strong>: 複数クエリの一括処理</li>
            <li><strong>メタデータ管理</strong>: 文書分類・検索・統計機能</li>
            <li><strong>レスポンシブUI</strong>: 改善されたレイアウトと視認性 <span class="feature-badge new">NEW</span></li>
        </ul>

        <h3>🔄 継続学習システム <span class="feature-badge new">NEW</span></h3>
        <ul>
            <li><strong>EWCベース継続学習</strong>: Fisher情報行列による重要パラメータの保護</li>
            <li><strong>破滅的忘却の防止</strong>: 以前のタスクの知識を保持しながら新タスクを学習</li>
            <li><strong>タスク管理</strong>: 複数の学習タスクの実行状況をリアルタイム監視</li>
            <li><strong>学習履歴管理</strong>: 完了したタスクの履歴と成果物の管理</li>
            <li><strong>メモリ効率化</strong>: 効率的なFisher行列管理による省メモリ実行</li>
            <li><strong>モデル選択</strong>: ベースモデルやファインチューニング済みモデルから選択可能</li>
        </ul>

        <h3>ファインチューニング手法</h3>
        <ul>
            <li><span class="emoji">🔥</span><strong>フルファインチューニング</strong>: 全パラメータ更新による高精度学習</li>
            <li><span class="emoji">⚡</span><strong>LoRA</strong>: パラメータ効率的学習（低メモリ）</li>
            <li><span class="emoji">💎</span><strong>QLoRA</strong>: 4bit/8bit量子化による超省メモリ学習</li>
            <li><span class="emoji">🧠</span><strong>EWC</strong>: 継続的学習による破滅的忘却の抑制</li>
            <li><span class="emoji">🔧</span><strong>自動量子化</strong>: モデルサイズに応じた最適化</li>
        </ul>

        <h3>✅ サポートモデル</h3>
        <p>最新のサポートモデルリストです。</p>
        
        <table>
            <thead>
                <tr>
                    <th>モデル名</th>
                    <th>タイプ</th>
                    <th>精度</th>
                    <th>推奨VRAM</th>
                    <th>タグ</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>Qwen/Qwen2.5-14B-Instruct</strong></td>
                    <td>CausalLM</td>
                    <td>bfloat16</td>
                    <td>32GB</td>
                    <td><code>multilingual</code>, <code>14b</code>, <code>instruct</code></td>
                </tr>
                <tr>
                    <td><strong>Qwen/Qwen2.5-32B-Instruct</strong></td>
                    <td>CausalLM</td>
                    <td>bfloat16</td>
                    <td>80GB</td>
                    <td><code>multilingual</code>, <code>32b</code>, <code>instruct</code></td>
                </tr>
                <tr>
                    <td><strong>cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese</strong></td>
                    <td>CausalLM</td>
                    <td>bfloat16</td>
                    <td>80GB</td>
                    <td><code>japanese</code>, <code>32b</code>, <code>deepseek</code></td>
                </tr>
                <tr>
                    <td><strong>cyberagent/calm3-22b-chat</strong></td>
                    <td>CausalLM</td>
                    <td>float16</td>
                    <td>48GB</td>
                    <td><code>japanese</code>, <code>22b</code>, <code>chat</code></td>
                </tr>
                <tr>
                    <td><strong>meta-llama/Meta-Llama-3.1-70B-Instruct</strong></td>
                    <td>CausalLM</td>
                    <td>bfloat16</td>
                    <td>160GB</td>
                    <td><code>multilingual</code>, <code>70b</code>, <code>instruct</code></td>
                </tr>
                <tr>
                    <td><strong>meta-llama/Meta-Llama-3.1-32B-Instruct</strong></td>
                    <td>CausalLM</td>
                    <td>bfloat16</td>
                    <td>80GB</td>
                    <td><code>multilingual</code>, <code>32b</code>, <code>instruct</code></td>
                </tr>
                <tr>
                    <td><strong>microsoft/Phi-3.5-32B-Instruct</strong></td>
                    <td>CausalLM</td>
                    <td>bfloat16</td>
                    <td>80GB</td>
                    <td><code>multilingual</code>, <code>32b</code>, <code>instruct</code></td>
                </tr>
                <tr>
                    <td><strong>microsoft/Orca-2-32B-Instruct</strong></td>
                    <td>CausalLM</td>
                    <td>bfloat16</td>
                    <td>80GB</td>
                    <td><code>multilingual</code>, <code>32b</code>, <code>instruct</code></td>
                </tr>
            </tbody>
        </table>

        <h3>GPU最適化</h3>
        <ul>
            <li><strong>Flash Attention 2</strong>: 注意機構の高速化</li>
            <li><strong>Gradient Checkpointing</strong>: メモリ使用量削減</li>
            <li><strong>Mixed Precision</strong>: FP16による計算高速化</li>
            <li><strong>マルチGPU対応</strong>: DataParallel/DistributedDataParallel</li>
        </ul>

        <h3>🧠 メモリ最適化（新機能）</h3>
        <ul>
            <li><strong>動的量子化</strong>: 32B/22Bモデルは4bit、7B/8Bモデルは8bit量子化を自動選択</li>
            <li><strong>CPUオフロード</strong>: GPUメモリ不足時の自動CPU実行</li>
            <li><strong>メモリ監視</strong>: リアルタイムメモリ使用量の監視と警告</li>
            <li><strong>モデルキャッシュ</strong>: 効率的なモデル再利用</li>
            <li><strong>最適化されたAPI</strong>: メモリ効率的なWeb API（<code>app/main_unified.py</code>）</li>
        </ul>

        <h2>📋 必要環境</h2>
        
        <h3>ハードウェア要件</h3>
        <ul>
            <li><strong>GPU</strong>: NVIDIA GPU（CUDA対応）</li>
            <li><strong>メモリ</strong>: 最低8GB VRAM（推奨16GB以上）</li>
            <li><strong>システムメモリ</strong>: 16GB以上推奨</li>
        </ul>

        <h3>ソフトウェア要件</h3>
        <ul>
            <li>Python 3.8以上（推奨3.11）</li>
            <li>CUDA 12.6+</li>
            <li>Docker & Docker Compose</li>
            <li>Git</li>
            <li>Ollama（Ollamaモデル統合のため）</li>
        </ul>

        <h2>🚀 クイックスタート</h2>
        
        <h3>1. リポジトリのクローン</h3>
        <pre><code>git clone https://github.com/kji-furuta/AI_FT_3.git
cd AI_FT_3</code></pre>

        <h3>2. Ollamaのインストール（初回のみ）</h3>
        <pre><code># Ollamaをインストール
curl -fsSL https://ollama.com/install.sh | sh

# Ollamaサービスを起動
ollama serve</code></pre>
        <p>※ 新しいターミナルウィンドウでOllamaを起動したままにしてください</p>

        <h3>3. Docker環境の起動（RAG統合版）</h3>
        
        <h4>自動ビルド（推奨）</h4>
        <pre><code># RAG依存関係も含めた完全ビルド＋起動＋テスト
./scripts/docker_build_rag.sh --no-cache</code></pre>

        <h4>手動ビルド</h4>
        <pre><code># 初回のみ：RAG統合版Dockerイメージビルド
cd docker
docker-compose up -d --build

# 2回目以降：通常起動（ビルド不要）
docker-compose up -d</code></pre>

        <h3>4. 統合Webインターフェースの起動</h3>
        
        <h4>方法1: 自動起動スクリプト（推奨）</h4>
        <pre><code># コンテナ内で統合インターフェース起動
docker exec ai-ft-container bash /workspace/scripts/start_web_interface.sh</code></pre>

        <h4>方法2: 手動起動（トラブルシューティング用）</h4>
        <pre><code># コンテナ内で直接起動（ログ確認用）
docker exec ai-ft-container python -m uvicorn app.main_unified:app --host 0.0.0.0 --port 8050 --reload</code></pre>

        <h4>方法3: バックグラウンド起動</h4>
        <pre><code># バックグラウンドで起動
docker exec -d ai-ft-container python -m uvicorn app.main_unified:app --host 0.0.0.0 --port 8050 --reload</code></pre>

        <h4>方法4: ファイル不足時の対処法</h4>
        <pre><code># 必要なファイルをコンテナにコピー
docker cp app/ ai-ft-container:/workspace/
docker cp templates/ ai-ft-container:/workspace/
docker cp src/ ai-ft-container:/workspace/

# Webサーバーを起動
docker exec -d ai-ft-container python -m uvicorn app.main_unified:app --host 0.0.0.0 --port 8050 --reload</code></pre>

        <h3>5. ブラウザでアクセス</h3>
        <ul>
            <li><strong>統合ダッシュボード</strong>: <a href="http://localhost:8050/" target="_blank">http://localhost:8050/</a></li>
            <li><strong>ファインチューニング</strong>: <a href="http://localhost:8050/finetune" target="_blank">http://localhost:8050/finetune</a></li>
            <li><strong>RAGシステム</strong>: <a href="http://localhost:8050/rag" target="_blank">http://localhost:8050/rag</a></li>
            <li><strong>継続学習</strong>: <a href="http://localhost:8050/continual" target="_blank">http://localhost:8050/continual</a></li>
            <li><strong>モデル管理</strong>: <a href="http://localhost:8050/models" target="_blank">http://localhost:8050/models</a></li>
        </ul>

        <h3>🎯 統合機能一覧</h3>
        <ul>
            <li><strong>統合ダッシュボード</strong>: システム状況とタスク管理</li>
            <li><strong>ファインチューニング</strong>: データアップロードと学習実行</li>
            <li><strong>RAGシステム</strong>: 土木道路設計文書の検索・質問応答 <span class="feature-badge new">NEW</span>
                <ul>
                    <li>文書アップロード・インデックス化</li>
                    <li>ハイブリッド検索（ベクトル+キーワード）</li>
                    <li>ストリーミング応答</li>
                    <li>バッチクエリ処理</li>
                    <li>文書統計・メタデータ管理</li>
                </ul>
            </li>
            <li><strong>継続学習</strong>: EWCベースの継続学習 <span class="feature-badge new">NEW</span></li>
            <li><strong>テキスト生成</strong>: 学習済みモデルでの推論</li>
            <li><strong>モデル管理</strong>: 利用可能モデルと学習済みモデル一覧</li>
            <li><strong>マニュアル</strong>: <code>/manual</code> - 詳細な利用方法</li>
            <li><strong>システム概要</strong>: <code>/system-overview</code> - 技術仕様</li>
        </ul>

        <h2>📚 使用方法</h2>
        
        <h3>🌐 Webインターフェース操作マニュアル</h3>
        
        <p>ブラウザで <code>http://localhost:8050</code> にアクセスして以下の機能を利用：</p>

        <h4>🏠 <strong>メインダッシュボード</strong> (<code>/</code>)</h4>
        <ul>
            <li><strong>システム状況確認</strong>: GPU使用状況、メモリ使用率、RAGシステム状態</li>
            <li><strong>機能ナビゲーション</strong>: 各機能へのクイックアクセス</li>
            <li><strong>リアルタイム監視</strong>: システムリソースの可視化</li>
        </ul>

        <h4>🎯 <strong>ファインチューニング</strong> (<code>/finetune</code>)</h4>
        <ol>
            <li><strong>データアップロード</strong>
                <ul>
                    <li>「ファイルを選択」ボタンをクリック</li>
                    <li>JSONL形式のトレーニングデータを選択</li>
                    <li>アップロード完了を確認</li>
                </ul>
            </li>
            <li><strong>モデル選択</strong>
                <ul>
                    <li>利用可能なベースモデルから選択</li>
                    <li>モデルサイズとVRAM要件を確認</li>
                    <li>推奨モデル: <code>cyberagent/calm3-22b-chat</code></li>
                </ul>
            </li>
            <li><strong>学習設定</strong>
                <ul>
                    <li><strong>学習手法選択</strong>:
                        <ul>
                            <li><code>LoRA</code>: 軽量学習（推奨）</li>
                            <li><code>QLoRA</code>: 4bit量子化学習</li>
                            <li><code>フルファインチューニング</code>: 全パラメータ更新</li>
                        </ul>
                    </li>
                    <li><strong>ハイパーパラメータ調整</strong>:
                        <ul>
                            <li>学習率: 1e-4 ~ 3e-4</li>
                            <li>バッチサイズ: 1-4（VRAMに応じて）</li>
                            <li>エポック数: 1-3</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>学習実行</strong>
                <ul>
                    <li>「学習開始」ボタンをクリック</li>
                    <li>リアルタイム進捗バーで監視</li>
                    <li>ログで詳細状況を確認</li>
                </ul>
            </li>
            <li><strong>学習完了</strong>
                <ul>
                    <li>モデル保存場所を確認</li>
                    <li>生成テストで品質評価</li>
                    <li>モデル管理ページで一覧表示</li>
                </ul>
            </li>
        </ol>

        <h4>🤖 <strong>テキスト生成</strong> (<code>/generate</code>)</h4>
        <ol>
            <li><strong>モデル選択</strong>
                <ul>
                    <li>学習済みモデル一覧から選択</li>
                    <li>モデル情報（サイズ、学習日時）を確認</li>
                </ul>
            </li>
            <li><strong>プロンプト入力</strong>
                <ul>
                    <li>テキストエリアに質問・指示を入力</li>
                    <li>日本語での自然な入力が可能</li>
                </ul>
            </li>
            <li><strong>生成パラメータ調整</strong>
                <ul>
                    <li><strong>温度 (Temperature)</strong>: 0.1-1.0（創造性の調整）</li>
                    <li><strong>最大長 (Max Length)</strong>: 100-2048（出力長の制限）</li>
                    <li><strong>Top-p</strong>: 0.1-1.0（多様性の調整）</li>
                </ul>
            </li>
            <li><strong>生成実行</strong>
                <ul>
                    <li>「生成開始」ボタンをクリック</li>
                    <li>ストリーミング表示でリアルタイム確認</li>
                    <li>結果のコピー・保存が可能</li>
                </ul>
            </li>
        </ol>

        <h4>🔍 <strong>RAGシステム</strong> (<code>/rag</code>) - 土木道路設計特化</h4>
        <ol>
            <li><strong>文書アップロード</strong>
                <ul>
                    <li>「ファイルを選択」でPDF文書をアップロード</li>
                    <li>文書タイトル、カテゴリ、タイプを設定</li>
                    <li>自動インデックス化の進行状況を確認</li>
                </ul>
            </li>
            <li><strong>インテリジェント検索</strong>
                <ul>
                    <li><strong>検索タイプ選択</strong>:
                        <ul>
                            <li><code>Hybrid</code>: ベクトル+キーワード検索（推奨）</li>
                            <li><code>Vector</code>: 意味的類似性検索</li>
                            <li><code>Keyword</code>: キーワードマッチング</li>
                        </ul>
                    </li>
                    <li><strong>検索クエリ入力</strong>: 自然言語での質問</li>
                    <li><strong>結果数調整</strong>: top_k（1-20件）</li>
                </ul>
            </li>
            <li><strong>質問応答</strong>
                <ul>
                    <li>専門的な質問を自然言語で入力</li>
                    <li>例: 「設計速度80km/hの道路の最小曲線半径は？」</li>
                    <li>引用情報付きの正確な回答を取得</li>
                </ul>
            </li>
            <li><strong>数値処理・検証</strong>
                <ul>
                    <li>自動数値抽出: 速度、長さ、勾配など</li>
                    <li>設計基準チェック: 道路構造令との適合性</li>
                    <li>単位変換: km↔m、km/h↔m/s</li>
                </ul>
            </li>
            <li><strong>バッチ処理</strong>
                <ul>
                    <li>複数クエリの一括処理</li>
                    <li>CSVファイルでの一括質問</li>
                    <li>結果の一括ダウンロード</li>
                </ul>
            </li>
            <li><strong>メタデータ管理</strong>
                <ul>
                    <li>文書一覧表示</li>
                    <li>カテゴリ別フィルタリング</li>
                    <li>統計情報の確認</li>
                </ul>
            </li>
        </ol>

        <h4>🔄 <strong>継続学習</strong> (<code>/continual</code>) <span class="feature-badge new">NEW</span></h4>
        <ol>
            <li><strong>タスクの作成</strong>
                <ul>
                    <li>タスク名とデータセットを指定</li>
                    <li>ベースモデルまたは既存のファインチューニング済みモデルを選択</li>
                    <li>EWCパラメータ（λ値）の設定</li>
                </ul>
            </li>
            <li><strong>学習の実行</strong>
                <ul>
                    <li>Fisher情報行列の計算</li>
                    <li>重要パラメータの保護しながら新タスクを学習</li>
                    <li>リアルタイムで進捗を監視</li>
                </ul>
            </li>
            <li><strong>タスク管理</strong>
                <ul>
                    <li>実行中のタスクの状態確認</li>
                    <li>完了したタスクの履歴表示</li>
                    <li>モデルのダウンロードと管理</li>
                </ul>
            </li>
        </ol>

        <h4>📊 <strong>モデル管理</strong> (<code>/models</code>)</h4>
        <ol>
            <li><strong>利用可能モデル</strong>
                <ul>
                    <li>ベースモデル一覧表示</li>
                    <li>モデル詳細情報（サイズ、VRAM要件）</li>
                    <li>ダウンロード状況の確認</li>
                </ul>
            </li>
            <li><strong>学習済みモデル</strong>
                <ul>
                    <li>ファインチューニング済みモデル一覧</li>
                    <li>学習日時、手法、サイズ情報</li>
                    <li>モデル削除・アーカイブ機能</li>
                </ul>
            </li>
            <li><strong>モデル変換</strong>
                <ul>
                    <li>Ollama形式への変換</li>
                    <li>GGUF形式への変換</li>
                    <li>変換進捗の監視</li>
                </ul>
            </li>
        </ol>

        <h4>⚙️ <strong>システム管理</strong></h4>
        <ol>
            <li><strong>システム情報</strong> (<code>/api/system-info</code>)
                <ul>
                    <li>GPU使用状況のリアルタイム監視</li>
                    <li>メモリ使用率の確認</li>
                    <li>RAGシステムの状態確認</li>
                </ul>
            </li>
            <li><strong>キャッシュ管理</strong>
                <ul>
                    <li>モデルキャッシュのクリア</li>
                    <li>メモリ最適化の実行</li>
                    <li>システムリセット</li>
                </ul>
            </li>
            <li><strong>ログ確認</strong>
                <ul>
                    <li>リアルタイムログ表示</li>
                    <li>エラーログの確認</li>
                    <li>システム診断</li>
                </ul>
            </li>
        </ol>

        <h4>📖 <strong>ドキュメント</strong></h4>
        <ol>
            <li><strong>利用マニュアル</strong> (<code>/manual</code>)
                <ul>
                    <li>詳細な操作手順</li>
                    <li>トラブルシューティング</li>
                    <li>よくある質問</li>
                </ul>
            </li>
            <li><strong>システム概要</strong> (<code>/system-overview</code>)
                <ul>
                    <li>技術仕様の詳細</li>
                    <li>アーキテクチャ説明</li>
                    <li>パフォーマンス情報</li>
                </ul>
            </li>
        </ol>

        <h2>🏗️ 土木道路設計特化型RAGシステム</h2>
        
        <h3>📖 概要</h3>
        <p>AI_FT_3には、土木道路設計分野に特化したRAG（Retrieval-Augmented Generation）システムが統合されています。このシステムは、道路構造令や設計基準書などの技術文書から正確な情報を検索し、引用情報付きの回答を生成します。</p>

        <h3>🎯 主要機能</h3>
        
        <h4>1. 数値処理エンジン</h4>
        <pre><code>from src.rag.specialized import NumericalProcessor, extract_numerical_values

# テキストから数値を自動抽出
text = "設計速度60km/h、最小曲線半径150m、縦断勾配5%とする。"
processor = NumericalProcessor()
result = processor.process_text(text)

print(f"抽出された数値: {len(result['numerical_values'])}個")
for value in result['numerical_values']:
    print(f"- {value['value']}{value['unit']} ({value['value_type']})")</code></pre>

        <h4>2. 設計基準検証</h4>
        <pre><code>from src.rag.specialized import check_design_standard

# 道路構造令に基づく適合性チェック
result = check_design_standard(
    value=135,  # 曲線半径135m
    value_type='curve_radius',
    unit='m',
    context={'design_speed': 60}
)

print(f"妥当性: {'○' if result.is_valid else '×'}")
print(f"メッセージ: {result.message}")</code></pre>

        <h4>3. バージョン管理</h4>
        <pre><code>from src.rag.specialized import create_version_manager

# 文書のバージョン管理
manager = create_version_manager()

# 新しいバージョンを作成
version = manager.create_version(
    document_id="road_standard_001",
    title="道路設計基準書 v1.1",
    content="設計速度は原則として60km/hとする...",
    parent_version_id="previous_version_id"
)

# バージョン間の差分を検出
diff = manager.compare_versions(version1_id, version2_id, content1, content2)
print(f"変更されたセクション: {len(diff.modified_sections)}個")</code></pre>

        <h4>4. ハイブリッド検索エンジン</h4>
        <pre><code>from src.rag.retrieval import HybridSearchEngine
from src.rag.indexing import QdrantVectorStore, EmbeddingModelFactory

# ハイブリッド検索の設定
vector_store = QdrantVectorStore(collection_name="road_documents")
embedding_model = EmbeddingModelFactory.create("multilingual-e5-large")

search_engine = HybridSearchEngine(
    vector_store=vector_store,
    embedding_model=embedding_model,
    vector_weight=0.7,
    keyword_weight=0.3
)

# 検索実行
from src.rag.retrieval import SearchQuery
query = SearchQuery(text="設計速度60km/hの最小曲線半径は？")
results = search_engine.search(query, top_k=5)</code></pre>

        <h4>5. 統合Web API インターフェース <span class="feature-badge new">NEW</span></h4>
        <pre><code># 統合APIサーバーの起動（RAG + ファインチューニング）
from app.main_unified import app
import uvicorn

# 単一ポートで全機能を提供
uvicorn.run(app, host="0.0.0.0", port=8050)</code></pre>

        <div class="success-box">
            <p><span class="emoji">✅</span><strong>統合完了</strong>: RAGシステムは http://localhost:8050/rag でアクセス可能です。</p>
        </div>

        <h2>📞 サポート</h2>
        <p>問題が発生した場合は、以下の方法でサポートを受けられます：</p>
        <ul>
            <li><strong>GitHub Issues</strong>: <a href="https://github.com/kji-furuta/AI_FT_3/issues" target="_blank">問題を報告</a></li>
            <li><strong>ドキュメント</strong>: <a href="/system-overview">システム概要</a>を参照</li>
            <li><strong>ログ確認</strong>: <code>docker logs ai-ft-container</code></li>
        </ul>

        <div class="info-box">
            <p><span class="emoji">💡</span><strong>ヒント</strong>: 最新の更新情報は、GitHubリポジトリのREADME.mdをご確認ください。</p>
        </div>
    </div>
</div>
{% endblock %}